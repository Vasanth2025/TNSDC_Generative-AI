{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfgsaPUw1z8y",
        "outputId": "c39d6970-d741-4dc1-b4e6-8f82d7f83177"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import random\n",
        "\n",
        "# Load pre-trained GPT model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# Function to generate a story with a specified prompt and style\n",
        "def generate_story(prompt, style_label):\n",
        "    # Concatenate prompt and style label\n",
        "    input_text = f\"{prompt} [{style_label}]\"\n",
        "\n",
        "    # Tokenize input text\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "\n",
        "    # Generate text based on input\n",
        "    max_length = 200  # Adjust maximum length as needed\n",
        "\n",
        "    # Set up nucleus sampling parameters\n",
        "    temperature = 0.7\n",
        "    top_p = 0.92  # Adjust top-p (nucleus) probability threshold\n",
        "    top_k = 0     # Set top-k to 0 for no restriction\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_length=max_length,\n",
        "        do_sample=True,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        top_k=top_k,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # Decode generated text\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    # Split text into sentences\n",
        "    sentences = generated_text.split('.')\n",
        "\n",
        "    # Filter out duplicate sentences\n",
        "    unique_sentences = list(set(sentences))\n",
        "\n",
        "    # Combine unique sentences into a single paragraph\n",
        "    generated_story = ' '.join(unique_sentences)\n",
        "\n",
        "    return generated_story.strip()  # Strip leading/trailing whitespace\n",
        "\n",
        "# Generate a story with a specified prompt and style\n",
        "prompt = \"In a land far away\"\n",
        "style_label = \"fairytale\"\n",
        "generated_story = generate_story(prompt, style_label)\n",
        "\n",
        "# Print the generated story\n",
        "print(\"Generated Story:\")\n",
        "print(generated_story)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waSbG2hU6GWo",
        "outputId": "4083265a-92d1-4d80-cd87-ffadc0273140"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Story:\n",
            "In a land far away [fairytale] of the ocean, it is quite clear that a living creature is almost always the result of evolution  But in these cases, the 'fish-egg' may not be the product of evolution  The fact that it is so strongly suggested suggests that the 'fish-egg' is a living creature that is generally considered to be the result of a single natural process, which is called evolution  But what is clear is that a number of these theories are not true, \n",
            "\n",
            "\n",
            "Of course, some of the theories that have been advanced against the theory of evolution, and in particular against the theory of evolution, are not even in harmony with the evidence, and have been thus abandoned  In fact, in certain species, such as the \"fish-egg\" which has been described as an 'egg' of the human eye, this is thought to be the cause of the migration of the 'fish-egg' to the other parts of the world\n"
          ]
        }
      ]
    }
  ]
}